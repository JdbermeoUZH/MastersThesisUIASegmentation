tta_mode: dae_and_diffusion # no_tta, gnn, gt, dae, dae_and_diffusion

start_new_exp: False
wandb_log: True

dataset: nuhs   # brain: hcp_t1, hcp_t2, abide_caltech, abide_stanford; wmh: nuhs, umc, vu
split:   test       # val, test
image_size: [1, 256, 256]
start: null       # Index of the test dataset to start at
stop:  null       # Index of the test dataset to stop at

seg_dir: /scratch_net/biwidl319/jbermeo/data/models/wmh/segmentation/umc/no_bg_supp_norm_w_3x3_06_06
load_best_cpt: True
classes_of_interest: null

num_workers: 0
device: cuda
seed: 0

bg_suppression_opts:
  type: fixed_value  # possible values: none, fixed_value, random_value
  bg_value: -0.5
  bg_value_min: -0.5
  bg_value_max: 1
  mask_source: thresholding  # possible values: thresholding, ground_truth
  thresholding: otsu  # possible values: isodata, li, mean, minimum, otsu, triangle, yen
  hole_filling: True


dae:
  wandb_project: mt-tta-wmh
  logdir: /scratch_net/biwidl319/jbermeo/logs/wmh/tta/debugging/dae_only/3_01/lr_1em3_grad_acc_1x1_conv_norm
  dae_dir: /scratch_net/biwidl319/jbermeo/data/models/wmh/dae/umc
  
  seg_with_bg_supp: False

  accumulate_over_volume: True
  batch_size: 32
  dataset_repetition: 1
  num_steps: 2700  # 500 for brain, 2700 for wmh
  update_dae_output_every: 270
  calculate_dice_every: 135  # 25 for brain, 135 for wmh (nuhs, umc, vu)
  alpha: 1.0
  beta: 0.25
  learning_rate: 0.001
  save_checkpoints: True
  const_aug_per_volume: False
  
  # Normalize intensities before segmentation
  update_norm_td_statistics: True
  manually_norm_img_before_seg_eval: True
  manually_norm_img_before_seg_tta: False
  normalization_strategy: standardize
  min_max_quantile: [0.025, 0.975]
  classes_of_interest: null

  # Suppress background x_norm 
  bg_supp_x_norm_eval: True
  bg_supp_x_norm_tta_dae: True
  bg_suppression_opts:
    type: fixed_value  # possible values: none, fixed_value, random_value
    bg_value: -0.5
    bg_value_min: -0.5
    bg_value_max: 1
    mask_source: thresholding  # possible values: thresholding, ground_truth
    thresholding: otsu  # possible values: isodata, li, mean, minimum, otsu, triangle, yen
    hole_filling: True
  
  augmentation:
    da_ratio: 0.25
    sigma: 20
    alpha: 0
    trans_min: 0
    trans_max: 0
    rot_min: 0
    rot_max: 0
    scale_min: 1.0
    scale_max: 1.0
    gamma_min: 0.5
    gamma_max: 2.0
    brightness_min: 0.0
    brightness_max: 0.1
    noise_mean: 0.0
    noise_std: 0.1


dae_and_ddpm:
  wandb_project: mt-tta-wmh
  logdir: /scratch_net/biwidl319/jbermeo/logs/wmh/tta/dae_and_cddpm/tests/04_02
  dae_dir: /scratch_net/biwidl319/jbermeo/data/models/wmh/dae/umc
  ddpm_dir: /scratch_net/biwidl319/jbermeo/logs/wmh/ddpm/umc/normalized_imgs/3x3_norm_filters/no_synthseg_labels/6_07/norm_q_0.001_0.999/batch_size_130_dim_64_dim_mults_1_2_2_2_uncond_rate_0.2_imgsize_128x128_no_class_balancing
  cpt_fn: 'model-4.pt' 
  
  # Loss weights
  dae_loss_alpha: 1.0
  ddpm_loss_beta: 1.0
  ddpm_uncond_loss_gamma: 0.0
  x_norm_regularization_eta: 1.0

  # DDPM loss params
  use_adaptive_beta: False
  adaptive_beta_momentum: 0.8
  classifier_free_guidance_weight: 100      # 30, or 100
  use_y_pred_for_ddpm_loss: True            # If False, and use_y_gt_for_ddpm_loss is False, then it will use the pseudo label from the DAE
  use_y_gt_for_ddpm_loss: False             # Only true for debugging
  detach_x_norm_from_ddpm_loss: False       # Use only gradients on the segmentation
  ddpm_loss_only_on_classes: null

  # Loss functions
  ddpm_loss: jacobian                       # jacobian, ssd, dds, pds 
  x_norm_regularization_loss: sq_grad       # null, sq_grad, zncc, rsq_sift, sift, mi 

  # Finetune batch normalization layers
  finetune_bn: False
  track_running_stats_bn: True
  subset_bn_layers: null                    # [0, 1]. If null, it will use all the layers

  # DAE term parameters  
  update_dae_output_every: 270              # 25 for brain, 135 for wmh (nuhs, umc, vu). Try 200 for brain and 270 for wmh for more stable convergence
  calculate_dice_every: 54    
  alpha: 1.0
  beta: 0.25 
  use_atlas_only_for_init: False
  dae_loss_except_on_classes: null
  
  # DDPM params
  min_max_intenities_norm_imgs: [0.1861095428466797, 1.2004246711730957]
  update_norm_td_statistics: True
  unconditional_rate: 0                     # It is the rate at which it does forward passes in unconditional mode
  #   switch and warmup
  use_ddpm_after_step: null                 # 500. If null, this condition is not used
  use_ddpm_after_dice: null                 # 0.5. If null, this condition is not used
  warmup_steps_for_ddpm_loss: 100           # 100. If null, no warmup is used
  #   minibatching
  minibatch_size_ddpm: 4
  frac_vol_diffusion_tta: 1.0
  #   sampling range for t's
  t_ddpm_range: [0.02, 0.98]                # [0.02, 0.98] 
  t_sampling_strategy: uniform              # uniform, stratified, one_per_volume
  
  sampling_timesteps: 100

  # Optimization parameters 
  num_steps: 2000                           # 500 for brain, 2700 for wmh
  learning_rate: 0.001
  accumulate_over_volume: True
  batch_size: 32
  dataset_repetition: 2
  save_checkpoints: True
  const_aug_per_volume: False

  # Normalize intensities before segmentation
  manually_norm_img_before_seg_val: True
  manually_norm_img_before_seg_tta: False
  normalization_strategy: standardize       # standardize, min_max, null
  min_max_quantile: [0.1, 0.975]
  classes_of_interest: null                   # 16 for wmh + synthseg, null for brain and wmh  

  # Supress background x_norm 
  bg_supp_x_norm_dae: True
  bg_supp_x_norm_ddpm: False
  bg_supp_x_norm_eval: False
  bg_suppression_opts:
    type: fixed_value                              # none, fixed_value, random_value
    bg_value: -0.5
    bg_value_min: -0.5
    bg_value_max: 1
    mask_source: thresholding               # thresholding, ground_truth
    thresholding: otsu                      # isodata, li, mean, minimum, otsu, triangle, yen
    hole_filling: True
  
  # Augmentation
  augmentation:
    da_ratio: 0.25
    sigma: 20
    alpha: 0
    trans_min: 0
    trans_max: 0
    rot_min: 0
    rot_max: 0
    scale_min: 1.0
    scale_max: 1.0
    gamma_min: 0.5
    gamma_max: 2.0
    brightness_min: 0.0
    brightness_max: 0.1
    noise_mean: 0.0
    noise_std: 0.0

diffusionTTA:
  wandb_project: mt-tta-diffusionTTA-tests
  logdir: /scratch_net/biwidl319/jbermeo/logs/wmh/tta/nuhs/test/diffusionTTA/06_12
  ddpm_dir: /scratch_net/biwidl319/jbermeo/logs/wmh/ddpm/umc/original_sd_imgs/3x3_norm_filters/no_synthseg_labels/6_09/norm_q_0.0_1.0/batch_size_130_dim_64_dim_mults_1_2_2_2_uncond_rate_0.2_imgsize_128x128_no_class_balancing
  cpt_fn: 'model-4.pt'

  num_steps:  20                          # 5 for original algo (it accumulates gradients over the entire volume for entire batch size)
  num_t_noise_pairs_per_img: 180
  batch_size: 48                          # Used for eval and during training
  minibatch_size_ddpm: 8                  # 8 for small GPUs, 32-64 for A6000
  dataset_repetition: 1
  const_aug_per_volume: True

  learning_rate: 0.00008                   # 8e-5
  learning_rate_norm: null                 # If null, takes the same value as learning_rate
  learning_rate_seg: null                  # If null, takes the same value as learning_rate
  learning_rate_ddpm: null                 # If null, takes the same value as learning_rate

  fit_norm_params: True
  fit_seg_params: True
  fit_ddpm_params: True

  ddpm_loss: jacobian                      # jacobian, ssd, dds, pds. Jacobian for original algo
  w_cfg: 0                                 # 0.0 for original algo 
  min_max_intenities_norm_imgs: [0, 1]
  pair_sampling_type: one_per_volume       # 'one_per_volume', 'one_per_image'
  t_ddpm_range: [0.02, 0.98]               # [0.02, 0.98] 
  t_sampling_strategy: uniform             # uniform, stratified
  unconditional_rate: 0                    # It is the rate at which it does forward passes in unconditional mode

  save_checkpoints: True
  calculate_dice_every: 1                  # We take very few steps, so we calculate the dice every step
  classes_of_interest: null                  # 16 for wmh + synthseg, null for brain and wmh  
  
  augmentation:
    da_ratio: 0.25
    sigma: 20
    alpha: 0
    trans_min: 0
    trans_max: 0
    rot_min: 0
    rot_max: 0
    scale_min: 1.0
    scale_max: 1.0
    gamma_min: 0.5
    gamma_max: 2.0
    brightness_min: 0.0
    brightness_max: 0.1
    noise_mean: 0.0
    noise_std: 0.0


diffusionTTA_and_DAE:
  wandb_project: mt-tta-diffusionTTA-tests
  logdir: /scratch_net/biwidl319/jbermeo/logs/wmh/tta/nuhs_w_synthseg_labels/test/diffusionTTA_and_DAE/06_12
  ddpm_dir: /scratch_net/biwidl319/jbermeo/logs/wmh/ddpm/umc/original_sd_imgs/3x3_norm_filters/no_synthseg_labels/6_09/norm_q_0.0_1.0/batch_size_130_dim_64_dim_mults_1_2_2_2_uncond_rate_0.2_imgsize_128x128_no_class_balancing
  cpt_fn: 'model-4.pt'
  dae_dir: /scratch_net/biwidl319/jbermeo/data/models/wmh/dae/umc

  num_steps:  2000                        # 5 for original algo (it accumulates gradients over the entire volume for entire batch size)
  batch_size: 48                          # Used for eval and during training
  minibatch_size_ddpm: 8                  # 8 for small GPUs, 64 for A6000
  dataset_repetition: 1
  const_aug_per_volume: True

  dae_loss_alpha: 1.0 
  ddpm_loss_beta: 1.0

  learning_rate: 0.00008                   # 8e-5
  learning_rate_norm: null                 # If null, takes the same value as learning_rate
  learning_rate_seg: null                  # If null, takes the same value as learning_rate
  learning_rate_ddpm: null                 # If null, takes the same value as learning_rate
  accumulate_over_volume: True

  fit_norm_params: True
  fit_seg_params: True
  fit_ddpm_params: True

  save_checkpoints: True
  calculate_dice_every: 135                # 25 for brain, 135 for wmh (nuhs, umc, vu)
  classes_of_interest: null                # 16 for wmh + synthseg, null for brain and wmh  

  # DAE Params
  update_dae_output_every: 270
  alpha: 1.0
  beta: 0.25
  bg_suppression_opts:
    type: fixed_value                       # none, fixed_value, random_value
    bg_value: -0.5
    bg_value_min: -0.5
    bg_value_max: 1
    mask_source: thresholding               # thresholding, ground_truth
    thresholding: otsu                      # isodata, li, mean, minimum, otsu, triangle, yen
    hole_filling: True
    
  # DDPM Params
  num_t_noise_pairs_per_img: 1             # 180 used in original algo
  ddpm_loss: jacobian                      # jacobian, ssd, dds, pds. Jacobian for original algo
  w_cfg: 100                                 # 0.0 for original algo 
  min_max_intenities_norm_imgs: [0, 1]
  pair_sampling_type: one_per_volume       # 'one_per_volume', 'one_per_image'
  t_ddpm_range: [0.02, 0.98]               # [0.02, 0.98] 
  t_sampling_strategy: uniform             # uniform, stratified
  unconditional_rate: 0                    # It is the rate at which it does forward passes in unconditional mode

  augmentation:
    da_ratio: 0.25
    sigma: 20
    alpha: 0
    trans_min: 0
    trans_max: 0
    rot_min: 0
    rot_max: 0
    scale_min: 1.0
    scale_max: 1.0
    gamma_min: 0.5
    gamma_max: 2.0
    brightness_min: 0.0
    brightness_max: 0.1
    noise_mean: 0.0
    noise_std: 0.0