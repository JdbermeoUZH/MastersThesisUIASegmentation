wandb_log:        True
wandb_run_name:   null
start_new_exp:    False
seed:             0
resume:           False
device:           cuda
checkpoint_best:  checkpoint_best.pth
checkpoint_last:  checkpoint_last.pth
dataset:          hcp_t1        # subcortical_structures: hcp_t1, hcp_t2, abide_caltech, abide_stanford;
                                # wmh: umc, nuhs, vu
                                # wmh + synthseg labels: umc_w_synthseg_labels, nuhs_w_synthseg_labels, vu_w_synthseg_labels

dae:
  wandb_project:                mt-dae_training
  batch_size:                   1
  num_workers:                  3
  image_size:                   [256, 256, 256]       # [256, 256, 256] for subcortical_structures, [48, 256, 256] for wmh
  rescale_factor:               [0.25, 1, 1]          # [0.25, 1, 1] for subcortical_structures, [1, 1, 1] for wmh
  epochs:                       2500                  # 2500 for subcortical_structures (hcp_t1, hcp_t2), 5000 for subcortical_structures (abide_caltech) and WMH (nuhs, umc, vu)
  validate_every:               50                    # 50 for subcortical_structures (hcp_t1, hcp_t2), 100 for subcortical_structures (abide_caltech) and WMH (nuhs, umc, vu)
  learning_rate:                1.0e-3
  validation_set_multiplier:    50
  logdir:                       $RESULTS_DIR/subcortical_structures/dae/debugging/hcp_t1/test_run
  
  # Loss function parameters
  epsilon:                      1e-10
  smooth:                       0
  fg_only:                      False 
  
  augmentation:
    da_ratio:             0.25
    sigma:                20
    alpha:                1000
    trans_min:            -10
    trans_max:            10
    rot_min:              -10
    rot_max:              10
    scale_min:            0.9
    scale_max:            1.1
    gamma_min:            1.0
    gamma_max:            1.0
    brightness_min:       0.0
    brightness_max:       0.0
    noise_mean:           0.0
    noise_std:            0.0
  
  deformation:
    mask_type:            squares_jigsaw # zeros / random_labels / jigsaw
    mask_radius:          10 # The mask will be a square with side length twice this number 
    mask_squares:         200
    is_num_masks_fixed:   False
    is_size_masks_fixed:  False

segmentation:
  batch_size:                   16
  num_workers:                  3
  image_size:                   [1, 256, 256]
  epochs:                       150  # 150 for subcortical_structures, 1000 for WMH (nuhs, umc)
  validate_every:               3
  learning_rate:                0.001
  logdir:                       $RESULTS_DIR/subcortical_structures/segmentation/hcp_t1/no_bg_supp_norm_w_3x3_conv
  wandb_project:                mt-segmentation_models
  
  with_bg_supression:           False

  # Loss function parameters
  epsilon:                      1e-10
  smooth:                       1e-5
  debug_mode:                   False
  fg_only:                      False  

  bg_suppression_opts:
    type:               none  # possible values: none, fixed_value, random_value, None means no background suppression
    bg_value:           -0.5
    bg_value_min:       -0.5
    bg_value_max:       1
    mask_source:        thresholding  # possible values: thresholding, ground_truth
    thresholding:       otsu  # possible values: isodata, li, mean, minimum, otsu, triangle, yen
    hole_filling:       True
  
  augmentation:
    da_ratio:           0.25
    sigma:              20
    alpha:              1000
    trans_min:          -10
    trans_max:          10
    rot_min:            -10
    rot_max:            10
    scale_min:          0.9
    scale_max:          1.1
    gamma_min:          0.5 #0.2     # Default 0.5
    gamma_max:          2.0 #5.0     # Default 2.0
    brightness_min:     0.0 #-0.2    # Default 0.0
    brightness_max:     0.1 #0.2     # Default 0.1
    noise_mean:         0.0
    noise_std:          0.1


ddpm_lucidrains:
  logdir:                       $RESULTS_DIR/subcortical_structures/ddpm/hcp_t1/normalized_imgs/3x3_norm_filters/4_15/batch_size_128_cond_by_concat
  wandb_project:                mt-ddpm

  batch_size:                   8
  gradient_accumulate_every:    16
  num_workers:                  3
  norm_with_nn_on_fly:          True
  use_original_imgs:            False
  one_hot_encode:               True
  normalize:                    min_max
  norm_q_range:                 [0.001, 0.999]
  image_size:                   [1, 256, 256]
  rescale_factor:               [1, 1, 1]
  condition_by_mult:            False
  also_unconditional:           False
  only_unconditional:           False
  unconditional_rate:           0.2
  class_weighing:               'none'   # 'none', 'balanced', 'custom'
  classes_of_interest:          null     # Lesion class is 16 for WMH + synthseg labels, otherwise it is 1 
  clip_classes_of_interest_at_factor: null  # null for no clipping, or 10. It is maximum ratio between weight of the class of interest and the weight of the other classes excluding the background

  objective:                    pred_v   # default is pred_v
  learning_rate:                8e-5     # 1e-4 in the constructor
  amp:                          True
  train_num_steps:              50000    # 7,000,000 or 100,000 in the original script
  timesteps:                    1000     # Range of noising steps to sample from during training. 1000 in the constructor  
  sampling_timesteps:           100      # Number of sampling steps to generate images. If less than 1000, will use DDIM sampling. If null, will be the same as timesteps => linear denoising steps
  save_and_sample_every:        2500     # 1000 in the constructor 
  num_validation_samples:       100      # Num of images to sample to check performance during training
  num_viz_samples:              50       # Must have an interger square root to store images in a square grid
  log_val_loss_every:           250  
  
  norm_dir:                     $MODEL_DIR/segmentation/subcortical_structures/hcp_t1/smoothing_denominator_1em10_diceloss_all_classes
  load_best_cpt:                True
  
  augmentation:                 
    da_ratio:           0.25
    sigma:              20
    alpha:              1000
    trans_min:          -10
    trans_max:          10
    rot_min:            -10
    rot_max:            10
    scale_min:          0.9
    scale_max:          1.1
    gamma_min:          0.5     # Default 0.5
    gamma_max:          2.0     # Default 2.0
    brightness_min:     0.0     # Default 0.0
    brightness_max:     0.1     # Default 0.1
    noise_mean:         0.0
    noise_std:          0.0

  bg_suppression_opts:          null
  deformation:                  null

  invalid_img:
    prob:               0.0
    bad_contrast:
      prob:             0.0
      gamma_min:        0.01
      gamma_max:        0.2 
    blurry:
      prob:             0.0
      blur_factor:      0.5
  
    invalid_labels:
      prob:             0.0
      jigsaw_cropping:    
        prob:           0.0
        mask_radius:    10
        mask_squares:   200
        is_num_masks_fixed:   False
        is_size_masks_fixed:  False
      random_pixel_erasure:
        prob:           0.0
        erasure_prob:   0.5
        erasure_size:   10
      random_label_erasure:
        prob:           0.0
        erasure_prob:   0.5
      random_component_erasure:
        prob:           0.0
        erasure_prob:   0.5
      random_label_mask:
        prob:           0.0
        random_noise_p: 0.5
        random_shapes_p: 0.5

cddpm:
  logdir:                       $RESULTS_DIR/subcortical_structures/lddpm/hcp_t1/normalized_imgs/3x3_norm_filters/debugging/test_run_DELETE_ME
  wandb_project:                mt-ddpm-debug_lddpm
  
  # Noising Parameters
  timesteps:                    1000     # Range of noising steps to sample from during training. 1000 in the constructor  
  rescale_betas_zero_snr:       False    # Whether to rescale the betas to have zero terminal SNR. Enables generating very bright and dark images: https://www.crosslabs.org//blog/diffusion-with-offset-noise 
  
  # Optimization Parameters
  train_num_steps:              50000    # 
  
  optimizer_type:               "adamW"  # Default is "adamW". Options are "adam", "adamW", "adamW8bit"

  objective:                    pred_v   # default is pred_v. Options are: 'pred_noise', 'pred_xt_m_1', 'pred_v', 'pred_x0'
  snr_weighting_gamma:          null     # When used, use 5.0 as it was the value found in the paper: https://arxiv.org/pdf/2303.09556

  learning_rate:                8e-5     # Default of 5e-6 in dreambooth. If scale_lr is True and effective batch size is 16, it becomes 8e-5  
  scale_lr:                     False    # Increase learning rate by the effective batch size (5e-6)
  batch_size:                   2        # Default 8 for A6000, 2 for GTX Titan Xp
  gradient_accumulate_every:    64       # Default 16 for A6000, 64 for GTX Titan Xp
  num_workers:                  2

  unconditional_rate:           0.2      # Rate of unconditional forward passes (Required to train CFG model)

  amp:                          False
  mixed_precision_type:         "fp16"   # Options are: 'fp16', 'bf16', or 'fp8'
  enable_xformers:              False
  gradient_checkpointing:       False
  allow_tf32:                   False

  # Evaluation parameters
  log_val_loss_every:           250      # Frequency to log denoising loss during training

  save_and_sample_every:        2500     # Frequency to log reconstruction/sampling losses during training
  sampling_timesteps:           100      # Number of sampling steps to generate images. If less than 1000, will use DDIM sampling. If null, will be the same as timesteps => linear denoising steps
  num_validation_samples:       100      # Num of images to sample to check performance during training
  num_viz_samples:              50       # Must have an interger square root to store images in a square grid
  
  calculate_fid:                True     # Whether to calculate FID during training
  
  # Preprocessing Parameters
  clamp_after_norm:             True     # Whether to clamp images after normalization and unnormalization 
  
  use_original_imgs:            False
  
  norm_with_nn_on_fly:          True      # Whether to normalize images on the fly
  norm_dir:                     $MODEL_DIR/segmentation/subcortical_structures/hcp_t1/smoothing_denominator_1em10_diceloss_all_classes
  load_best_cpt:                True

  normalize:                    min_max
  norm_q_range:                 [0.001, 0.999]
  min_max_intensity:            null      # If null, it is calculated from the training set
  
  rescale_factor:               [1, 1, 1]
  image_size:                   [1, 256, 256]
  
  augmentation:                 
    da_ratio:           0.25
    sigma:              20
    alpha:              1000
    trans_min:          -10
    trans_max:          10
    rot_min:            -10
    rot_max:            10
    scale_min:          0.9
    scale_max:          1.1
    gamma_min:          0.5     # Default 0.5
    gamma_max:          2.0     # Default 2.0
    brightness_min:     0.0     # Default 0.0
    brightness_max:     0.1     # Default 0.1
    noise_mean:         0.0
    noise_std:          0.0

  invalid_img:
    prob:               0.0
    bad_contrast:
      prob:             0.0
      gamma_min:        0.01
      gamma_max:        0.2 
    blurry:
      prob:             0.0
      blur_factor:      0.5
  
    invalid_labels:
      prob:             0.0
      jigsaw_cropping:    
        prob:           0.0
        mask_radius:    10
        mask_squares:   200
        is_num_masks_fixed:   False
        is_size_masks_fixed:  False
      random_pixel_erasure:
        prob:           0.0
        erasure_prob:   0.5
        erasure_size:   10
      random_label_erasure:
        prob:           0.0
        erasure_prob:   0.5
      random_component_erasure:
        prob:           0.0
        erasure_prob:   0.5
      random_label_mask:
        prob:           0.0
        random_noise_p: 0.5
        random_shapes_p: 0.5


lddpm:
  logdir:                       $RESULTS_DIR/subcortical_structures/lddpm/hcp_t1/normalized_imgs/3x3_norm_filters/debugging/test_run_DELETE_ME
  wandb_project:                mt-ddpm-debug_lddpm
  
  # Model Parameters
  fit_emb_for_cond_img:         True     # Fit an embedding network for the conditional image
  vae_path:                     "runwayml/stable-diffusion-v1-5"     # Path to the VAE model to use for the embedding network  
  vae_pretrained_on_nat_images: True    # Whether the VAE model was pretrained on natural images
  
  # Noising Parameters
  timesteps:                    1000     # Range of noising steps to sample from during training. 1000 in the constructor  
  rescale_betas_zero_snr:       False    # Whether to rescale the betas to have zero terminal SNR. Enables generating very bright and dark images: https://www.crosslabs.org//blog/diffusion-with-offset-noise 
  
  # Optimization Parameters
  train_num_steps:              50000    # 
  
  optimizer_type:               "adamW"  # Default is "adamW". Options are "adam", "adamW", "adamW8bit"

  objective:                    pred_v   # default is pred_v. Options are: 'pred_noise', 'pred_xt_m_1', 'pred_v', 'pred_x0'
  snr_weighting_gamma:          null     # When used, use 5.0 as it was the value found in the paper: https://arxiv.org/pdf/2303.09556

  learning_rate:                8e-5     # Default of 5e-6 in dreambooth. If scale_lr is True and effective batch size is 16, it becomes 8e-5  
  scale_lr:                     False    # Increase learning rate by the effective batch size (5e-6)
  batch_size:                   2        # Default 8 for A6000, 2 for GTX Titan Xp
  gradient_accumulate_every:    64       # Default 16 for A6000, 64 for GTX Titan Xp
  num_workers:                  2

  unconditional_rate:           0.2      # Rate of unconditional forward passes (Required to train CFG model)

  amp:                          False
  mixed_precision_type:         "fp16"   # Options are: 'fp16', 'bf16', or 'fp8'
  enable_xformers:              False
  gradient_checkpointing:       False
  allow_tf32:                   False

  # Evaluation parameters
  log_val_loss_every:           250      # Frequency to log denoising loss during training

  save_and_sample_every:        2500     # Frequency to log reconstruction/sampling losses during training
  sampling_timesteps:           100      # Number of sampling steps to generate images. If less than 1000, will use DDIM sampling. If null, will be the same as timesteps => linear denoising steps
  num_validation_samples:       100      # Num of images to sample to check performance during training
  num_viz_samples:              50       # Must have an interger square root to store images in a square grid
  
  calculate_fid:                True     # Whether to calculate FID during training
  
  # Preprocessing Parameters
  clamp_after_norm:             True     # Whether to clamp images after normalization and unnormalization 
  
  use_original_imgs:            False
  
  norm_with_nn_on_fly:          True      # Whether to normalize images on the fly
  norm_dir:                     $MODEL_DIR/segmentation/subcortical_structures/hcp_t1/smoothing_denominator_1em10_diceloss_all_classes
  load_best_cpt:                True

  normalize:                    min_max
  norm_q_range:                 [0.001, 0.999]
  min_max_intensity:            null      # If null, it is calculated from the training set
  
  rescale_factor:               [1, 1, 1]
  image_size:                   [1, 256, 256]
  
  augmentation:                 
    da_ratio:           0.25
    sigma:              20
    alpha:              1000
    trans_min:          -10
    trans_max:          10
    rot_min:            -10
    rot_max:            10
    scale_min:          0.9
    scale_max:          1.1
    gamma_min:          0.5     # Default 0.5
    gamma_max:          2.0     # Default 2.0
    brightness_min:     0.0     # Default 0.0
    brightness_max:     0.1     # Default 0.1
    noise_mean:         0.0
    noise_std:          0.0

  invalid_img:
    prob:               0.0
    bad_contrast:
      prob:             0.0
      gamma_min:        0.01
      gamma_max:        0.2 
    blurry:
      prob:             0.0
      blur_factor:      0.5
  
    invalid_labels:
      prob:             0.0
      jigsaw_cropping:    
        prob:           0.0
        mask_radius:    10
        mask_squares:   200
        is_num_masks_fixed:   False
        is_size_masks_fixed:  False
      random_pixel_erasure:
        prob:           0.0
        erasure_prob:   0.5
        erasure_size:   10
      random_label_erasure:
        prob:           0.0
        erasure_prob:   0.5
      random_component_erasure:
        prob:           0.0
        erasure_prob:   0.5
      random_label_mask:
        prob:           0.0
        random_noise_p: 0.5
        random_shapes_p: 0.5