dae:
  channel_size:                     [16, 32, 64]
  channels_bottleneck:              128
  skips:                            [False, True, True]
  n_dimensions:                     3


normalization_2D:
  n_layers:                         3
  image_channels:                   1
  channel_size:                     16
  kernel_size:                      3
  activation:                       rbf
  batch_norm:                       True
  residual:                         True
  n_dimensions:                     2


segmentation_2D:
  image_channels:                   1
  channel_size:                     [16, 32, 64]
  channels_bottleneck:              128
  skips:                            [True, True, True]
  n_dimensions:                     2


normalization_3D:
  n_layers:                         3
  image_channels:                   1
  channel_size:                     16            # In the original implementation, this is 16
  kernel_size:                      3
  activation:                       rbf
  batch_norm:                       True
  residual:                         True
  n_dimensions:                     3


segmentation_3D:
  image_channels:                   1
  channel_size:                     [2, 4, 16]    # It might be also [2, 4, 8]
  channels_bottleneck:              64            # It might be also 32
  skips:                            [True, True, True]
  n_dimensions:                     3

lddpm_unet:
  dim:                              64            # Number of filters in the first layer. Default 64
  dim_mults:                        [1, 2, 2, 2]  # Multipliers for the number of filters in each layer. Default: [1, 2, 4, 8]
  use_x_attention:                  True          # Use cross-attention. 
  time_embedding_dim:               512           # Dimension of the time embedding. Default 512, Only used if use_x_attention is True
  cond_type:                        'sum'         # 'sum', 'concat'

ddpm_unet:
  dim:                              64            # Number of filters in the first layer. Default 64
  dim_mults:                        [1, 2, 4, 8]  # Multipliers for the number of filters in each layer. Default: [1, 2, 4, 8]
  use_x_attention:                  True          # Use cross-attention. 
  channels:                         1             # Number of input channels
  time_embedding_dim:               512           # Dimension of the time embedding. Default 512, Only used if use_x_attention is True
  cond_type:                        'concat'      # 'sum', 'concat'

ddpm_unet_oai:
  num_channels:                     128            # Number of filters in the first layer. Default 64
  channel_mult:                     [1, 2, 3, 4]  # Multipliers for the number of filters in each layer. Default: [1, 2, 4, 8]
  channels:                         1             # Number of input channels
  num_res_blocks:                   3             # Default is 2, but for bigger datasets they use 3
  num_heads:                        1             # Default is 4 on the original paper when used on Imagenet